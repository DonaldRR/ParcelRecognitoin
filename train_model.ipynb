{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "import keras\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, GRU, Bidirectional, Input\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Concatenate, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import gensim\n",
    "from CapsuleLayers import Capsule\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLoad X, y\\nX = np.load(X_SAVE_PATH)\\ny = np.load(y_SAVE_PATH)\\nX_word = X\\nX_char = [X[i].replace(' ','') for i in range(len(X))]\\n\\n\\n# Encode labels\\nfrom sklearn.preprocessing import OneHotEncoder\\nenc = OneHotEncoder()\\ny = enc.fit_transform(y.reshape((-1,1))).toarray()\\n\\n# Make char vocabulary\\nchar2vec_f = open(CHAR2VEC_PATH, 'r')\\nchar2vec_txt = char2vec_f.readlines()\\n\\n# tokenize char\\ntokenizer_char = Tokenizer(char_level=True)\\ntokenizer_char.fit_on_texts(X_char)\\nX_char_seq = tokenizer_char.texts_to_sequences(X_char)\\n# get char dictionary\\nchar_dictionary = tokenizer_char.word_index\\n\\n# tokenize word\\ntokenizer_word = Tokenizer()\\ntokenizer_word.fit_on_texts(X_word)\\nX_word_seq = tokenizer_word.texts_to_sequences(X_word)\\n# get word dictionary\\nword_dictionary = tokenizer_word.word_index\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load X, y\n",
    "X = np.load(X_SAVE_PATH)\n",
    "y = np.load(y_SAVE_PATH)\n",
    "X_word = X\n",
    "X_char = [X[i].replace(' ','') for i in range(len(X))]\n",
    "\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y.reshape((-1,1))).toarray()\n",
    "\n",
    "# Make char vocabulary\n",
    "char2vec_f = open(CHAR2VEC_PATH, 'r')\n",
    "char2vec_txt = char2vec_f.readlines()\n",
    "\n",
    "# tokenize char\n",
    "tokenizer_char = Tokenizer(char_level=True)\n",
    "tokenizer_char.fit_on_texts(X_char)\n",
    "X_char_seq = tokenizer_char.texts_to_sequences(X_char)\n",
    "# get char dictionary\n",
    "char_dictionary = tokenizer_char.word_index\n",
    "\n",
    "# tokenize word\n",
    "tokenizer_word = Tokenizer()\n",
    "tokenizer_word.fit_on_texts(X_word)\n",
    "X_word_seq = tokenizer_word.texts_to_sequences(X_word)\n",
    "# get word dictionary\n",
    "word_dictionary = tokenizer_word.word_index\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load X, y\n",
    "X = np.load(X_SAVE_PATH)\n",
    "y = np.load(y_SAVE_PATH)\n",
    "X_char = [X[i].replace(' ','') for i in range(len(X))]\n",
    "\n",
    "# create char tokenizer and char embedding_matrix\n",
    "char2vec_f = open(\"char_embedding/glove.840B.300d-char.txt\",'r')\n",
    "char2vecs = char2vec_f.readlines()\n",
    "\n",
    "char_tokenizer = Tokenizer(char_level=True,oov_token=0)\n",
    "char_embd_matrix = []\n",
    "\n",
    "\n",
    "for line in char2vecs:\n",
    "    tokens = line.split(' ')\n",
    "    char = tokens[0]\n",
    "    vector =[float(token) for token in tokens[1:]]\n",
    "    char_tokenizer.fit_on_texts(char)\n",
    "    char_embd_matrix.append(vector)\n",
    "char_embd_matrix.insert(0,np.random.uniform(size=len(char_embd_matrix[0])).tolist())\n",
    "char_embd_matrix = np.asarray(char_embd_matrix)\n",
    "\n",
    "\n",
    "# create word tokenizer and word embedding matrix\n",
    "word2vec_f = open(\"word_embedding/glove.6B.300d.txt\",'r')\n",
    "word_tokenizer = Tokenizer(oov_token=0)\n",
    "word_embd_matrix = []\n",
    "\n",
    "count = 0\n",
    "while(count < 8000):\n",
    "    line = word2vec_f.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    tokens = line.split(' ')\n",
    "    word = tokens[0]\n",
    "    vector = [float(token) for token in tokens[1:]]\n",
    "    word_tokenizer.fit_on_texts(word)\n",
    "    word_embd_matrix.append(vector)\n",
    "    count+=1\n",
    "word_embd_matrix.insert(0,np.random.uniform(size=len(word_embd_matrix[0])).tolist())\n",
    "word_embd_matrix = np.asarray(word_embd_matrix)\n",
    "\n",
    "\n",
    "# convert string to sequence\n",
    "X_char_seq = char_tokenizer.texts_to_sequences(X_char)\n",
    "X_word_seq = word_tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# one hot encode y\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y.reshape((-1,1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Make char embedding dictionary\\nchar_dict = {}\\nprint('# Making char vocabulary ...')\\nfor i in tqdm(range(len(char2vec_txt))):\\n    char2vec_i = char2vec_txt[i].split(' ')\\n    char_dict[char2vec_i[0]] = np.array(char2vec_i[1:], dtype=np.float32)\\n    \\n# Make char embedding matrix\\nprint('# Making char embedding matrix ...')\\nchar_embd_matrix = []\\nfor word, i in char_dict.items():\\n    try:\\n        vec = char_dict[word]\\n        char_embd_matrix.append(vec)\\n    except:\\n        print('No such char {}'.format(word))\\nchar_embd_matrix = np.array(char_embd_matrix)\\nchar_embd_matrix = np.insert(char_embd_matrix, [0], np.zeros((300)), axis=0)\\n\\n# Make word embedding matrix\\nprint('# Loading word embedding model ...')\\nword_dict = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_PATH, binary=True)\\nprint('# Making word embedding matrix ...')\\nword_embd_matrix = []\\nfor word, i in tqdm(word_dictionary.items()):\\n    try:\\n        vec = word_dict[word]\\n        word_embd_matrix.append(vec)\\n    except:\\n        print('No such word {}',format(word))\\nword_embd_matrix = np.array(word_embd_matrix)\\nword_embd_matrix = np.insert(word_embd_matrix, [0], np.zeros((300)), axis=0)\\n\\n\\n# Transfer non-meaningful chars to zeros\\nfor i in range(len(X_char_seq)):\\n    for j in range(len(X_char_seq[i])):\\n        if X_char_seq[i][j]>len(char_embd_matrix)-1:\\n            X_char_seq[i][j] = 0\\n\\n# Transfer non-meaningful words to zeros\\nfor i in range(len(X_word_seq)):\\n    for j in range(len(X_word_seq[i])):\\n        if X_word_seq[i][j]>len(word_embd_matrix)-1:\\n            X_word_seq[i][j] = 0\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Make char embedding dictionary\n",
    "char_dict = {}\n",
    "print('# Making char vocabulary ...')\n",
    "for i in tqdm(range(len(char2vec_txt))):\n",
    "    char2vec_i = char2vec_txt[i].split(' ')\n",
    "    char_dict[char2vec_i[0]] = np.array(char2vec_i[1:], dtype=np.float32)\n",
    "    \n",
    "# Make char embedding matrix\n",
    "print('# Making char embedding matrix ...')\n",
    "char_embd_matrix = []\n",
    "for word, i in char_dict.items():\n",
    "    try:\n",
    "        vec = char_dict[word]\n",
    "        char_embd_matrix.append(vec)\n",
    "    except:\n",
    "        print('No such char {}'.format(word))\n",
    "char_embd_matrix = np.array(char_embd_matrix)\n",
    "char_embd_matrix = np.insert(char_embd_matrix, [0], np.zeros((300)), axis=0)\n",
    "\n",
    "# Make word embedding matrix\n",
    "print('# Loading word embedding model ...')\n",
    "word_dict = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_PATH, binary=True)\n",
    "print('# Making word embedding matrix ...')\n",
    "word_embd_matrix = []\n",
    "for word, i in tqdm(word_dictionary.items()):\n",
    "    try:\n",
    "        vec = word_dict[word]\n",
    "        word_embd_matrix.append(vec)\n",
    "    except:\n",
    "        print('No such word {}',format(word))\n",
    "word_embd_matrix = np.array(word_embd_matrix)\n",
    "word_embd_matrix = np.insert(word_embd_matrix, [0], np.zeros((300)), axis=0)\n",
    "\n",
    "\n",
    "# Transfer non-meaningful chars to zeros\n",
    "for i in range(len(X_char_seq)):\n",
    "    for j in range(len(X_char_seq[i])):\n",
    "        if X_char_seq[i][j]>len(char_embd_matrix)-1:\n",
    "            X_char_seq[i][j] = 0\n",
    "\n",
    "# Transfer non-meaningful words to zeros\n",
    "for i in range(len(X_word_seq)):\n",
    "    for j in range(len(X_word_seq[i])):\n",
    "        if X_word_seq[i][j]>len(word_embd_matrix)-1:\n",
    "            X_word_seq[i][j] = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Padding ...\n"
     ]
    }
   ],
   "source": [
    "# Padding seqences \n",
    "print('# Padding ...')\n",
    "max_len_char = max([len(X_char_seq[i]) for i in range(len(X_char_seq))])\n",
    "X_char_seq = pad_sequences(sequences=X_char_seq, maxlen=max_len_char)\n",
    "\n",
    "max_len_word = max([len(X_word_seq[i]) for i in range(len(X_word_seq))])\n",
    "X_word_seq = pad_sequences(sequences=X_word_seq, maxlen=max_len_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 268/3193 [00:00<00:01, 2675.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3193/3193 [00:00<00:00, 3320.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load images files names\n",
    "train_imgs_fn = []\n",
    "for roots, dirs, files in os.walk(TRAIN_IMG_PATH):\n",
    "    train_imgs_fn = files\n",
    "\n",
    "# Reshape images to (150, 500)\n",
    "print('# Loading images ...')\n",
    "X_train_imgs = []\n",
    "for i in tqdm(range(len(train_imgs_fn))):\n",
    "    img_ = cv2.imread(os.path.join(TRAIN_IMG_PATH, train_imgs_fn[i]))\n",
    "    X_train_imgs.append(cv2.resize(img_, (300,150)))\n",
    "X_train_imgs = np.array(X_train_imgs)\n",
    "# X_train_imgs = np.mean(X_train_imgs, axis=3)\n",
    "# X_train_imgs = np.expand_dims(X_train_imgs, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Building model ...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 261)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 79)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 261, 300)     28500       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 79, 300)      2400300     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 64)           63936       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 64)           63936       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 64)           63936       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 64)           63936       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 64)           63936       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 64)           63936       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 64)           63936       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 64)           63936       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 64)           63936       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 64)           63936       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 64)           63936       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 64)           63936       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 64)           63936       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 64)           63936       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1, 64)        0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 64)        0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 64)        0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 64)        0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 64)        0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 64)        0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 64)        0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1, 64)        0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 64)        0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1, 64)        0           bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 64)        0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1, 64)        0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 64)        0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1, 64)        0           bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "capsule (Capsule)               (None, 5, 8)         2560        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "capsule_1 (Capsule)             (None, 5, 8)         2560        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_2 (Capsule)             (None, 5, 8)         2560        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_3 (Capsule)             (None, 5, 8)         2560        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_4 (Capsule)             (None, 5, 8)         2560        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_5 (Capsule)             (None, 5, 8)         2560        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_6 (Capsule)             (None, 5, 8)         2560        lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_7 (Capsule)             (None, 5, 8)         2560        lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_8 (Capsule)             (None, 5, 8)         2560        lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_9 (Capsule)             (None, 5, 8)         2560        lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_10 (Capsule)            (None, 5, 8)         2560        lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "capsule_11 (Capsule)            (None, 5, 8)         2560        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "capsule_12 (Capsule)            (None, 5, 8)         2560        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "capsule_13 (Capsule)            (None, 5, 8)         2560        lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 40)           0           capsule[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 40)           0           capsule_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 40)           0           capsule_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 40)           0           capsule_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 40)           0           capsule_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 40)           0           capsule_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 40)           0           capsule_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 40)           0           capsule_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 40)           0           capsule_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 40)           0           capsule_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 40)           0           capsule_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 40)           0           capsule_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 40)           0           capsule_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 40)           0           capsule_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80)           0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 80)           0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 80)           0           flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 80)           0           flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 80)           0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 80)           0           flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           2592        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2592        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           2592        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           2592        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           2592        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           2592        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           2592        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16)           0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            17          dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            17          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            17          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            17          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            17          dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            17          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            17          dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,381,703\n",
      "Trainable params: 3,381,703\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "print('# Building model ...')\n",
    "\n",
    "# # InceptionV3 module\n",
    "# inx = InceptionV3(include_top=False, weights='imagenet', input_shape=(150, 300, 3))\n",
    "# for layer in inx.layers:\n",
    "#     layer.trainable=False\n",
    "# input_inx = inx.input\n",
    "# inx = inx.get_layer('activation_3').output\n",
    "# inx = MaxPooling2D(2)(inx)\n",
    "# inx = Flatten()(inx)\n",
    "\n",
    "# RNN char module\n",
    "input_char = Input(shape=(max_len_char, ))\n",
    "char_embd = Embedding(input_dim=len(char_embd_matrix),\n",
    "                 output_dim=300,\n",
    "                weights=[char_embd_matrix],\n",
    "                mask_zero=True)(input_char)\n",
    "\n",
    "# RNN word module\n",
    "input_word = Input(shape=(max_len_word,))\n",
    "word_embd = Embedding(input_dim=len(word_embd_matrix),\n",
    "                 output_dim=300,\n",
    "                weights=[word_embd_matrix],\n",
    "                mask_zero=True)(input_word)\n",
    "\n",
    "outputs = []\n",
    "for i in range(7):\n",
    "    char = Bidirectional(GRU(32))(char_embd)\n",
    "    char = Lambda(lambda x:tf.expand_dims(x, axis=1))(char)\n",
    "    char = Capsule(5, 8, 5)(char)\n",
    "    char = Flatten()(char)\n",
    "    \n",
    "    word = Bidirectional(GRU(32))(word_embd)\n",
    "    word = Lambda(lambda x:tf.expand_dims(x, axis=1))(word)\n",
    "    word = Capsule(5, 8, 5)(word)\n",
    "    word = Flatten()(word)\n",
    "    \n",
    "    out = Concatenate()([char, word])\n",
    "    out = Dense(32)(out)\n",
    "    out = Dense(16)(out)\n",
    "    out = Dropout(0.3)(out)\n",
    "    out = Dense(1, activation='sigmoid')(out)\n",
    "    outputs.append(out)\n",
    "model = Model(inputs=[input_char, input_word], outputs=outputs)\n",
    "# model = Model(inputs=input_inx, outputs=outputs)\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Spliting data ...\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "print('# Spliting data ...')\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_img_train, X_img_valid,  y_train, y_valid = train_test_split(X_train_imgs,y, test_size=0.2)\n",
    "X_char_train, X_char_valid, X_word_train, X_word_valid, y_train, y_valid = train_test_split(X_char_seq, \n",
    "                                                                                            X_word_seq,\n",
    "                                                                                            y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donald/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2554 samples, validate on 639 samples\n",
      "Epoch 1/30\n",
      "2554/2554 [==============================] - 217s 85ms/step - loss: 2.7074 - dense_2_loss: 0.2558 - dense_5_loss: 0.4662 - dense_8_loss: 0.2292 - dense_11_loss: 0.4830 - dense_14_loss: 0.5624 - dense_17_loss: 0.3285 - dense_20_loss: 0.3821 - dense_2_binary_accuracy: 0.9667 - dense_5_binary_accuracy: 0.8567 - dense_8_binary_accuracy: 0.9804 - dense_11_binary_accuracy: 0.8610 - dense_14_binary_accuracy: 0.7866 - dense_17_binary_accuracy: 0.8645 - dense_20_binary_accuracy: 0.8132 - val_loss: 1.9834 - val_dense_2_loss: 0.2140 - val_dense_5_loss: 0.3288 - val_dense_8_loss: 0.1678 - val_dense_11_loss: 0.2970 - val_dense_14_loss: 0.4337 - val_dense_17_loss: 0.2768 - val_dense_20_loss: 0.2653 - val_dense_2_binary_accuracy: 0.9593 - val_dense_5_binary_accuracy: 0.9296 - val_dense_8_binary_accuracy: 0.9922 - val_dense_11_binary_accuracy: 0.9421 - val_dense_14_binary_accuracy: 0.8059 - val_dense_17_binary_accuracy: 0.8873 - val_dense_20_binary_accuracy: 0.8701\n",
      "Epoch 2/30\n",
      "2554/2554 [==============================] - 197s 77ms/step - loss: 1.7294 - dense_2_loss: 0.1626 - dense_5_loss: 0.2886 - dense_8_loss: 0.1598 - dense_11_loss: 0.2509 - dense_14_loss: 0.3680 - dense_17_loss: 0.2510 - dense_20_loss: 0.2485 - dense_2_binary_accuracy: 0.9761 - dense_5_binary_accuracy: 0.9287 - dense_8_binary_accuracy: 0.9859 - dense_11_binary_accuracy: 0.9483 - dense_14_binary_accuracy: 0.8731 - dense_17_binary_accuracy: 0.8868 - dense_20_binary_accuracy: 0.8665 - val_loss: 1.4628 - val_dense_2_loss: 0.1349 - val_dense_5_loss: 0.2351 - val_dense_8_loss: 0.1156 - val_dense_11_loss: 0.1940 - val_dense_14_loss: 0.3095 - val_dense_17_loss: 0.2342 - val_dense_20_loss: 0.2395 - val_dense_2_binary_accuracy: 0.9765 - val_dense_5_binary_accuracy: 0.9468 - val_dense_8_binary_accuracy: 0.9922 - val_dense_11_binary_accuracy: 0.9546 - val_dense_14_binary_accuracy: 0.8920 - val_dense_17_binary_accuracy: 0.8905 - val_dense_20_binary_accuracy: 0.8701\n",
      "Epoch 3/30\n",
      "2554/2554 [==============================] - 196s 77ms/step - loss: 1.3584 - dense_2_loss: 0.1153 - dense_5_loss: 0.2094 - dense_8_loss: 0.1103 - dense_11_loss: 0.1810 - dense_14_loss: 0.2823 - dense_17_loss: 0.2295 - dense_20_loss: 0.2306 - dense_2_binary_accuracy: 0.9792 - dense_5_binary_accuracy: 0.9444 - dense_8_binary_accuracy: 0.9859 - dense_11_binary_accuracy: 0.9561 - dense_14_binary_accuracy: 0.9068 - dense_17_binary_accuracy: 0.8908 - dense_20_binary_accuracy: 0.8716 - val_loss: 1.3071 - val_dense_2_loss: 0.1048 - val_dense_5_loss: 0.2094 - val_dense_8_loss: 0.0706 - val_dense_11_loss: 0.1608 - val_dense_14_loss: 0.2832 - val_dense_17_loss: 0.2210 - val_dense_20_loss: 0.2573 - val_dense_2_binary_accuracy: 0.9750 - val_dense_5_binary_accuracy: 0.9296 - val_dense_8_binary_accuracy: 0.9922 - val_dense_11_binary_accuracy: 0.9577 - val_dense_14_binary_accuracy: 0.8998 - val_dense_17_binary_accuracy: 0.8998 - val_dense_20_binary_accuracy: 0.8623\n",
      "Epoch 4/30\n",
      "2554/2554 [==============================] - 214s 84ms/step - loss: 1.1881 - dense_2_loss: 0.0892 - dense_5_loss: 0.1716 - dense_8_loss: 0.0871 - dense_11_loss: 0.1332 - dense_14_loss: 0.2526 - dense_17_loss: 0.2214 - dense_20_loss: 0.2330 - dense_2_binary_accuracy: 0.9796 - dense_5_binary_accuracy: 0.9464 - dense_8_binary_accuracy: 0.9859 - dense_11_binary_accuracy: 0.9659 - dense_14_binary_accuracy: 0.9127 - dense_17_binary_accuracy: 0.8947 - dense_20_binary_accuracy: 0.8696 - val_loss: 1.1912 - val_dense_2_loss: 0.1058 - val_dense_5_loss: 0.1510 - val_dense_8_loss: 0.0629 - val_dense_11_loss: 0.1349 - val_dense_14_loss: 0.2860 - val_dense_17_loss: 0.2243 - val_dense_20_loss: 0.2264 - val_dense_2_binary_accuracy: 0.9765 - val_dense_5_binary_accuracy: 0.9468 - val_dense_8_binary_accuracy: 0.9922 - val_dense_11_binary_accuracy: 0.9562 - val_dense_14_binary_accuracy: 0.8795 - val_dense_17_binary_accuracy: 0.8905 - val_dense_20_binary_accuracy: 0.8732\n",
      "Epoch 5/30\n",
      "  64/2554 [..............................] - ETA: 3:00 - loss: 1.1529 - dense_2_loss: 0.0975 - dense_5_loss: 0.1033 - dense_8_loss: 0.1052 - dense_11_loss: 0.1316 - dense_14_loss: 0.2281 - dense_17_loss: 0.2474 - dense_20_loss: 0.2398 - dense_2_binary_accuracy: 0.9688 - dense_5_binary_accuracy: 0.9688 - dense_8_binary_accuracy: 0.9844 - dense_11_binary_accuracy: 0.9688 - dense_14_binary_accuracy: 0.9219 - dense_17_binary_accuracy: 0.8906 - dense_20_binary_accuracy: 0.8594"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c07368fc978e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# model.fit(x=X_img_train, y=[y_train[:,i] for i in range(7)], validation_data=[X_img_valid, y_valid], batch_size=64, epochs=30)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.fit(x=[X_char_train, X_word_train], y=[y_train[:,i] for i in range(7)], \n\u001b[0;32m----> 5\u001b[0;31m           validation_data=[[X_char_valid, X_word_valid], [y_valid[:,i] for i in range(7)]], batch_size=64, epochs=30)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2973\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2974\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2975\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1395\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1396\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print('# Training ...')\n",
    "# model.fit(x=X_img_train, y=[y_train[:,i] for i in range(7)], validation_data=[X_img_valid, y_valid], batch_size=64, epochs=30)\n",
    "model.fit(x=[X_char_train, X_word_train], y=[y_train[:,i] for i in range(7)], \n",
    "          validation_data=[[X_char_valid, X_word_valid], [y_valid[:,i] for i in range(7)]], batch_size=64, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./clf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveBbox(img_n, box_n):\n",
    "    bbox = np.load(os.path.join(test_split_img_dir, img_n, 'bbox.npy'))\n",
    "    return bbox.item()[box_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_img_dir = '/home/donald/PycharmProjects/Atos/data/test_split_img'\n",
    "test_rotated_img_dir = '/home/donald/PycharmProjects/Atos/data/test_rotated_img_box/'\n",
    "test_string_data_dir = '/home/donald/Blaine/string_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictBbox(string_data_dir, n, img_dir=test_split_img_dir, save_name='test.jpg'):\n",
    "    # Read stings & string_belong\n",
    "    str_f = open(os.path.join(string_data_dir,'OCRed_string.txt'))\n",
    "    belong_f = open(os.path.join(string_data_dir, 'string_belong.txt'))\n",
    "\n",
    "    test_str = str_f.readlines()\n",
    "    test_str_belong = belong_f.readlines()\n",
    "    test_str_belong = [test_str_belong[i].replace('\\n', '').split('\\t') for i in range(len(test_str_belong))]\n",
    "\n",
    "    # Generate Input Data\n",
    "    test_char = [test_str[i].replace('\\n','').replace(' ','') for i in range(len(test_str))]\n",
    "    test_word = [test_str[i].replace('\\n','') for i in range(len(test_str_belong))]\n",
    "\n",
    "    test_char = tokenizer_char.texts_to_sequences(test_char)\n",
    "    test_word = tokenizer_word.texts_to_sequences(test_word)\n",
    "\n",
    "    test_char = pad_sequences(sequences=test_char, maxlen=max_len_char)\n",
    "    test_word = pad_sequences(sequences=test_word, maxlen=max_len_word)\n",
    "    \n",
    "    # Predict\n",
    "    pred = model.predict(x=[test_char, test_word])\n",
    "    \n",
    "    # Top n indices\n",
    "    inds = [np.argpartition(np.reshape(a=pred[i], newshape=(len(pred[i]))), -n)[-n:]\n",
    "           for i in range(7)]\n",
    "    \n",
    "    # Resulting Boxes\n",
    "    results = []\n",
    "    for i in range(len(inds)):\n",
    "        ind = inds[i]\n",
    "        boxes = []\n",
    "        for ind_ in ind:\n",
    "            boxes.append(retrieveBbox(test_str_belong[ind_][0][:-4], test_str_belong[ind_][1]))\n",
    "        result = np.mean(boxes, axis=0)\n",
    "        results.append(result)\n",
    "    results = np.array(results, dtype=int)\n",
    "\n",
    "    # Plot \n",
    "#     img = cv2.imread(os.path.join(img_dir, test_str_belong[0][0]))\n",
    "#     img_ = img.copy()\n",
    "#     for i in range(len(results)):\n",
    "#         img_ = cv2.rectangle(img, tuple(results[i][0]), tuple(results[i][2]), color=(0,255,0), thickness=2)\n",
    "#     plt.imshow(img_)\n",
    "    \n",
    "    # Save\n",
    "#     cv2.imwrite('./testing/{}.jpg'.format(save_name), img_)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string_dir = '/home/donald/Blaine/SPLIT_OUTPUT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_n = []\n",
    "for roots, dirs, files in os.walk(test_string_dir):\n",
    "    images_n.extend(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/302 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/302 [00:19<1:36:11, 19.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2/302 [00:40<1:41:25, 20.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3/302 [01:02<1:43:05, 20.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 4/302 [01:16<1:34:53, 19.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/302 [01:29<1:28:39, 17.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6/302 [02:00<1:39:05, 20.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7/302 [02:37<1:50:34, 22.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 8/302 [03:38<2:13:36, 27.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 9/302 [04:06<2:13:50, 27.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10/302 [04:19<2:06:27, 25.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 11/302 [04:26<1:57:42, 24.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 12/302 [04:50<1:57:08, 24.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 13/302 [05:18<1:57:55, 24.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 14/302 [05:37<1:55:39, 24.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 15/302 [06:20<2:01:16, 25.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 16/302 [06:26<1:55:04, 24.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 17/302 [06:48<1:54:00, 24.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 18/302 [07:15<1:54:29, 24.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 19/302 [08:00<1:59:19, 25.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 20/302 [08:53<2:05:16, 26.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 21/302 [09:29<2:07:06, 27.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 22/302 [09:40<2:03:10, 26.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 23/302 [10:02<2:01:44, 26.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 24/302 [10:31<2:02:00, 26.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 25/302 [10:53<2:00:38, 26.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 26/302 [11:04<1:57:29, 25.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 27/302 [11:24<1:56:09, 25.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 28/302 [11:33<1:53:09, 24.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 29/302 [11:44<1:50:32, 24.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 30/302 [11:51<1:47:33, 23.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 31/302 [12:34<1:49:56, 24.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 32/302 [12:50<1:48:17, 24.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 33/302 [13:01<1:46:14, 23.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 34/302 [13:35<1:47:06, 23.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 35/302 [13:57<1:46:31, 23.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 36/302 [14:08<1:44:30, 23.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 37/302 [14:25<1:43:17, 23.39s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 38/302 [15:02<1:44:27, 23.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 39/302 [15:30<1:44:37, 23.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 40/302 [15:55<1:44:21, 23.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 41/302 [16:07<1:42:40, 23.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 42/302 [16:42<1:43:24, 23.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 43/302 [17:05<1:42:54, 23.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 44/302 [17:30<1:42:37, 23.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 45/302 [17:34<1:40:24, 23.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 46/302 [18:03<1:40:29, 23.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 47/302 [18:28<1:40:13, 23.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 48/302 [18:45<1:39:13, 23.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 49/302 [19:20<1:39:53, 23.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 50/302 [19:28<1:38:06, 23.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 51/302 [19:55<1:38:03, 23.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 52/302 [20:22<1:37:58, 23.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 53/302 [20:41<1:37:14, 23.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 54/302 [21:04<1:36:47, 23.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 55/302 [21:35<1:36:57, 23.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 56/302 [22:06<1:37:07, 23.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 57/302 [22:29<1:36:39, 23.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 58/302 [22:42<1:35:31, 23.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 59/302 [23:15<1:35:48, 23.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 60/302 [23:19<1:34:03, 23.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 61/302 [23:44<1:33:47, 23.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 62/302 [23:49<1:32:11, 23.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 63/302 [24:05<1:31:24, 22.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 64/302 [24:18<1:30:25, 22.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 65/302 [24:37<1:29:48, 22.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 66/302 [24:51<1:28:51, 22.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 67/302 [25:18<1:28:46, 22.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 68/302 [25:41<1:28:23, 22.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 69/302 [26:34<1:29:45, 23.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 70/302 [26:57<1:29:21, 23.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 71/302 [27:08<1:28:17, 22.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 72/302 [27:16<1:27:08, 22.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 73/302 [27:56<1:27:38, 22.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 74/302 [28:16<1:27:06, 22.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 75/302 [28:32<1:26:21, 22.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 76/302 [29:13<1:26:55, 23.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 77/302 [29:23<1:25:52, 22.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 78/302 [29:57<1:26:03, 23.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 79/302 [30:07<1:25:02, 22.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 80/302 [31:21<1:27:00, 23.52s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 81/302 [31:35<1:26:12, 23.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 82/302 [31:56<1:25:40, 23.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 83/302 [32:18<1:25:15, 23.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 84/302 [32:31<1:24:25, 23.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 85/302 [32:46<1:23:39, 23.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 86/302 [32:50<1:22:30, 22.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 87/302 [33:13<1:22:06, 22.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 88/302 [33:26<1:21:19, 22.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 89/302 [33:55<1:21:10, 22.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 90/302 [34:21<1:20:55, 22.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 91/302 [35:03<1:21:16, 23.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 92/302 [35:22<1:20:44, 23.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 93/302 [35:48<1:20:28, 23.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 94/302 [36:03<1:19:48, 23.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 95/302 [36:24<1:19:19, 22.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 96/302 [36:34<1:18:30, 22.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 97/302 [36:51<1:17:53, 22.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 98/302 [37:05<1:17:13, 22.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 99/302 [37:17<1:16:28, 22.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 100/302 [37:38<1:16:02, 22.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 101/302 [37:51<1:15:20, 22.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 102/302 [38:22<1:15:15, 22.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 103/302 [38:57<1:15:15, 22.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 104/302 [39:29<1:15:11, 22.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 105/302 [39:36<1:14:19, 22.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 106/302 [39:48<1:13:36, 22.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 107/302 [40:11<1:13:14, 22.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 108/302 [40:35<1:12:54, 22.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 109/302 [40:42<1:12:04, 22.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 110/302 [41:11<1:11:53, 22.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 111/302 [41:24<1:11:14, 22.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 112/302 [41:32<1:10:28, 22.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 113/302 [41:54<1:10:05, 22.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 114/302 [42:34<1:10:13, 22.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 115/302 [42:46<1:09:33, 22.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 116/302 [42:57<1:08:53, 22.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 117/302 [43:11<1:08:18, 22.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 118/302 [43:22<1:07:38, 22.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 119/302 [43:43<1:07:13, 22.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 120/302 [43:57<1:06:39, 21.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 121/302 [44:08<1:06:01, 21.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 122/302 [44:24<1:05:31, 21.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 123/302 [44:49<1:05:14, 21.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 124/302 [45:02<1:04:40, 21.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 125/302 [45:11<1:03:59, 21.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 126/302 [45:29<1:03:32, 21.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 127/302 [46:08<1:03:34, 21.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 128/302 [46:31<1:03:14, 21.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 129/302 [46:57<1:02:58, 21.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 130/302 [47:19<1:02:36, 21.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 131/302 [47:44<1:02:18, 21.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 132/302 [48:06<1:01:57, 21.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 133/302 [48:11<1:01:14, 21.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 134/302 [48:24<1:00:41, 21.68s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 135/302 [48:36<1:00:08, 21.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 136/302 [49:11<1:00:02, 21.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 137/302 [49:37<59:46, 21.73s/it]  \u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 138/302 [49:53<59:16, 21.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 139/302 [50:20<59:02, 21.73s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 140/302 [50:31<58:27, 21.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 141/302 [50:45<57:57, 21.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 142/302 [51:04<57:33, 21.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 143/302 [51:38<57:25, 21.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 144/302 [51:59<57:03, 21.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 145/302 [52:28<56:49, 21.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 146/302 [52:35<56:12, 21.62s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 147/302 [52:57<55:50, 21.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 148/302 [53:12<55:22, 21.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 149/302 [53:45<55:11, 21.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 150/302 [54:30<55:14, 21.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 151/302 [55:01<55:01, 21.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 152/302 [55:24<54:40, 21.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 153/302 [55:49<54:22, 21.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 154/302 [56:34<54:21, 22.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 155/302 [56:40<53:44, 21.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 156/302 [56:47<53:08, 21.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 157/302 [57:11<52:49, 21.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 158/302 [57:48<52:40, 21.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 159/302 [58:00<52:10, 21.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 160/302 [58:38<52:02, 21.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 161/302 [59:19<51:57, 22.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 162/302 [59:45<51:38, 22.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 163/302 [1:00:14<51:22, 22.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 164/302 [1:00:23<50:49, 22.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 165/302 [1:00:38<50:20, 22.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 166/302 [1:00:59<49:58, 22.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 167/302 [1:01:17<49:33, 22.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 168/302 [1:01:32<49:04, 21.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 169/302 [1:01:39<48:31, 21.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 170/302 [1:01:56<48:05, 21.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 171/302 [1:02:09<47:36, 21.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 172/302 [1:02:26<47:11, 21.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 173/302 [1:02:41<46:44, 21.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 174/302 [1:02:53<46:16, 21.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 175/302 [1:03:29<46:04, 21.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 176/302 [1:03:54<45:45, 21.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 177/302 [1:04:11<45:19, 21.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 178/302 [1:04:22<44:50, 21.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 179/302 [1:04:45<44:29, 21.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 180/302 [1:04:58<44:02, 21.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 181/302 [1:05:34<43:50, 21.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 182/302 [1:05:48<43:23, 21.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 183/302 [1:06:29<43:14, 21.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 184/302 [1:06:56<42:55, 21.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 185/302 [1:07:18<42:33, 21.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 186/302 [1:07:29<42:05, 21.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 187/302 [1:07:51<41:44, 21.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 188/302 [1:08:09<41:19, 21.75s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 189/302 [1:08:46<41:07, 21.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 190/302 [1:08:59<40:40, 21.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 191/302 [1:09:04<40:08, 21.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 192/302 [1:09:20<39:43, 21.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 193/302 [1:10:03<39:33, 21.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 194/302 [1:10:42<39:21, 21.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 195/302 [1:10:52<38:53, 21.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 196/302 [1:11:06<38:27, 21.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 197/302 [1:11:17<38:00, 21.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 198/302 [1:11:54<37:46, 21.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 199/302 [1:12:03<37:17, 21.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 200/302 [1:12:21<36:53, 21.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 201/302 [1:13:00<36:41, 21.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 202/302 [1:13:05<36:11, 21.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 203/302 [1:13:29<35:50, 21.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 204/302 [1:13:40<35:23, 21.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 205/302 [1:13:43<34:53, 21.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 206/302 [1:13:53<34:26, 21.52s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 207/302 [1:13:59<33:57, 21.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 208/302 [1:14:21<33:36, 21.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 209/302 [1:14:37<33:12, 21.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 210/302 [1:14:51<32:47, 21.39s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 211/302 [1:15:30<32:34, 21.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 212/302 [1:16:12<32:21, 21.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 213/302 [1:16:42<32:03, 21.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 214/302 [1:17:09<31:43, 21.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 215/302 [1:17:11<31:14, 21.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 216/302 [1:17:25<30:49, 21.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 217/302 [1:17:57<30:32, 21.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 218/302 [1:18:11<30:07, 21.52s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 219/302 [1:18:30<29:45, 21.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 220/302 [1:18:39<29:19, 21.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 221/302 [1:18:59<28:57, 21.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 222/302 [1:19:27<28:38, 21.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 223/302 [1:19:40<28:13, 21.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 224/302 [1:19:47<27:47, 21.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 225/302 [1:19:58<27:22, 21.33s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 226/302 [1:20:15<26:59, 21.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 227/302 [1:20:47<26:41, 21.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 228/302 [1:21:09<26:20, 21.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 229/302 [1:21:15<25:54, 21.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 230/302 [1:21:24<25:29, 21.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 231/302 [1:21:49<25:09, 21.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 232/302 [1:22:06<24:46, 21.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 233/302 [1:22:39<24:28, 21.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 234/302 [1:22:57<24:06, 21.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 235/302 [1:23:08<23:42, 21.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 236/302 [1:23:21<23:18, 21.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 237/302 [1:23:30<22:54, 21.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 238/302 [1:23:56<22:34, 21.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 239/302 [1:24:25<22:15, 21.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 240/302 [1:24:52<21:55, 21.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 241/302 [1:25:04<21:32, 21.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 242/302 [1:25:18<21:09, 21.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 243/302 [1:25:59<20:52, 21.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 244/302 [1:26:36<20:35, 21.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 245/302 [1:26:48<20:11, 21.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 246/302 [1:27:35<19:56, 21.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 247/302 [1:27:44<19:32, 21.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 248/302 [1:27:59<19:09, 21.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 249/302 [1:29:41<19:05, 21.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 250/302 [1:29:50<18:41, 21.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 251/302 [1:30:18<18:21, 21.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 252/302 [1:31:10<18:05, 21.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 253/302 [1:31:38<17:45, 21.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 254/302 [1:31:56<17:22, 21.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 255/302 [1:32:25<17:02, 21.75s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 256/302 [1:33:00<16:42, 21.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 257/302 [1:33:26<16:21, 21.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 258/302 [1:33:40<15:58, 21.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 259/302 [1:33:51<15:34, 21.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 260/302 [1:34:04<15:11, 21.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 261/302 [1:34:30<14:50, 21.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 262/302 [1:34:48<14:28, 21.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 263/302 [1:35:18<14:08, 21.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 264/302 [1:35:43<13:46, 21.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 265/302 [1:36:18<13:26, 21.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 266/302 [1:36:45<13:05, 21.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 267/302 [1:36:55<12:42, 21.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 268/302 [1:37:18<12:20, 21.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 269/302 [1:38:20<12:03, 21.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 270/302 [1:38:49<11:42, 21.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 271/302 [1:39:08<11:20, 21.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 272/302 [1:39:41<10:59, 21.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 273/302 [1:39:52<10:36, 21.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 274/302 [1:40:07<10:13, 21.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 275/302 [1:40:41<09:53, 21.97s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 276/302 [1:41:12<09:32, 22.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 277/302 [1:41:20<09:08, 21.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 278/302 [1:41:42<08:46, 21.95s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 279/302 [1:42:18<08:26, 22.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 280/302 [1:42:25<08:02, 21.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 281/302 [1:42:45<07:40, 21.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 282/302 [1:43:11<07:19, 21.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 283/302 [1:43:21<06:56, 21.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 284/302 [1:44:02<06:35, 21.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 285/302 [1:44:11<06:12, 21.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 286/302 [1:44:51<05:51, 22.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 287/302 [1:45:17<05:30, 22.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 288/302 [1:45:51<05:08, 22.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 289/302 [1:46:27<04:47, 22.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 290/302 [1:46:38<04:24, 22.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 291/302 [1:47:02<04:02, 22.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 292/302 [1:47:19<03:40, 22.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 293/302 [1:47:53<03:18, 22.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 294/302 [1:48:35<02:57, 22.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 295/302 [1:48:44<02:34, 22.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 296/302 [1:49:04<02:12, 22.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 297/302 [1:49:18<01:50, 22.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 298/302 [1:49:27<01:28, 22.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 299/302 [1:49:41<01:06, 22.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 300/302 [1:50:04<00:44, 22.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 301/302 [1:51:32<00:22, 22.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 302/302 [1:51:52<00:00, 22.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i in tqdm(range(len(images_n))):\n",
    "    results[images_n[i]] = predictBbox(os.path.join(test_string_dir, images_n[i]), 2, save_name=images_n[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['image_name','found_1','X1_1','Y1_1','X2_1','Y2_1','X3_1','Y3_1','X4_1','Y4_1',\n",
    "                          'found_2','X1_2','Y1_2','X2_2','Y2_2','X3_2','Y3_2','X4_2','Y4_2',\n",
    "                          'found_3','X1_3','Y1_3','X2_3','Y2_3','X3_3','Y3_3','X4_3','Y4_3',\n",
    "                          'found_4','X1_4','Y1_4','X2_4','Y2_4','X3_4','Y3_4','X4_4','Y4_4',\n",
    "                          'found_5','X1_5','Y1_5','X2_5','Y2_5','X3_5','Y3_5','X4_5','Y4_5',\n",
    "                          'found_6','X1_6','Y1_6','X2_6','Y2_6','X3_6','Y3_6','X4_6','Y4_6',\n",
    "                          'found_7','X1_7','Y1_7','X2_7','Y2_7','X3_7','Y3_7','X4_7','Y4_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
